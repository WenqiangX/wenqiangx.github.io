<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Wenqiang Xu</title> <meta name="author" content="Wenqiang Xu"> <meta name="description" content="Wenqiang Xu's academic homepage. "> <meta name="keywords" content="Wenqiang Xu, 徐文强, wenqiangxu, Wenqiang, Robot, Learning, Computer, Vision"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?3c822a6ce67e7669dd81ad8b9149f588"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://wenqiangx.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Wenqiang</span> Xu </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg?122e7e19c215c7611c554f6072d200d9" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> </div> </div> <div class="clearfix"> <p>I am actively seeking a postdoctoral position. My PhD and MS was completed at the School of SEIEE, Shanghai Jiao Tong University, under the supervision of <strong>Prof. Cewu Lu</strong>. Prior to this, I earned my bachelor’s degree from the School of the Gifted Young at the University of Science and Technology of China.</p> <p>I once visited NUS, I was advised by <a href="https://linsats.github.io/" rel="external nofollow noopener" target="_blank">Prof. Shao Lin</a> and collaborated with <a href="https://haroldsoh.com/" rel="external nofollow noopener" target="_blank">Prof. Harold Soh</a>.</p> <p>I founded and lead the <a href="https://robotflow.ai" rel="external nofollow noopener" target="_blank">RobotFlow</a>, which contains full-stack solutions to multi-modal perception, planning and control, and multiphysics &amp; musculoskeletal simulation. This infrastructure is supporting all research projects in my team!</p> <p>My research spectrum is shifting from object understanding to human-centric learning, with an interest in areas such as <strong>brain</strong>-robot interfaces, <strong>muscle</strong>-actuated control, <strong>dexterous</strong> manipulation and visual-<strong>tactile</strong> perception. Something cool is ongoing!</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jun 16, 2025</th> <td> 2 papers are accepted by IROS 2025. Both are selected as <strong>Oral</strong> representation. </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 31, 2024</th> <td> 10 papers are accepted by CVPR/IROS/RA-L/PAMI/<strong>Nature Communications</strong>, including 1 IROS <strong>Oral Pitch</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 31, 2023</th> <td> 6 papers are accepted by CVPR/RSS/ICCV/CoRL, including 1 ICCV <strong>Oral</strong>. </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 31, 2022</th> <td> 6 papers are accepted by IROS/CVPR/CoRL/ICRA/TIP, including 1 IROS <strong>Best RoboCup Award &amp; Best Paper Finalist</strong>, 1 CVPR <strong>Oral</strong>, 1 CoRL <strong>Oral</strong>. </td> </tr> </table> </div> </div> <h2><a href="/talks/" style="color: inherit;">talks</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jun 16, 2025</th> <td> Some in-door seminars. Not disclosure. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 29, 2024</th> <td> Empowered AI at AIEC. Thank Harvard Club of Wuxi for the invitation. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 16, 2022</th> <td> RFUniverse at Stanford Vision and Learning Lab. Thank Chen Wang for the invitation. </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/vitam-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/vitam-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/vitam-1400.webp"></source> <img src="/assets/img/publication_preview/vitam.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="vitam.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vitam" class="col-sm-8"> <div class="title">Capturing forceful interaction with deformable objects using a deep learning-powered stretchable tactile array</div> <div class="author"> Chunpeng Jiang*, <strong>Wenqiang Xu*</strong>, Yutong Li, Zhenjun Yu, Longchun Wang, Xiaotong Hu, Zhengyi Xie, Qingkun Liu, Bin Yang, Xiaolin Wang, Wenxin Du, Tutian Tang, Dongzhe Zheng, Siqiong Yao, Cewu Lu, and Jingquan Liu</div> <div class="periodical"> <em>Nature Communications</em>, 2024 <span style="color:red;font-weight: bold;"></span> </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41467-024-53654-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/jeffsonyu/ViTaM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">vitam</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Capturing forceful interaction with deformable objects using a deep learning-powered stretchable tactile array}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jiang*, Chunpeng and Xu*, Wenqiang and Li, Yutong and Yu, Zhenjun and Wang, Longchun and Hu, Xiaotong and Xie, Zhengyi and Liu, Qingkun and Yang, Bin and Wang, Xiaolin and Du, Wenxin and Tang, Tutian and Zheng, Dongzhe and Yao, Siqiong and Lu, Cewu and Liu, Jingquan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Communications}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Publishing Group UK London}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/dipgrasp-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/dipgrasp-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/dipgrasp-1400.webp"></source> <img src="/assets/img/publication_preview/dipgrasp.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="dipgrasp.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="dipgrasp" class="col-sm-8"> <div class="title">DiPGrasp: Parallel Local Searching for Efficient Differentiable Grasp Planning</div> <div class="author"> <strong>Wenqiang Xu*</strong>, Jieyi Zhang*, Tutian Tang, Zhenjun Yu, Yutong Li, and Cewu Lu</div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2024 <span style="color:red;font-weight: bold;"></span> </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2408.04738" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://dipgrasp.robotflow.ai" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">dipgrasp</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{DiPGrasp: Parallel Local Searching for Efficient Differentiable Grasp Planning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu*, Wenqiang and Zhang*, Jieyi and Tang, Tutian and Yu, Zhenjun and Li, Yutong and Lu, Cewu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/diffstir.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/diffstir.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/diffstir.gif-1400.webp"></source> <img src="/assets/img/publication_preview/diffstir.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="diffstir.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="diffstir" class="col-sm-8"> <div class="title">Differentiable Fluid Physics Parameter Identification By Stirring and For Stirring</div> <div class="author"> <strong>Wenqiang Xu*</strong>, Dongzhe Zheng*, Yutong Li, Jieji Ren, and Cewu Lu</div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems</em>, 2024 <span style="color:red;font-weight: bold;">Oral Pitch</span> </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2311.05137" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://diffstir.robotflow.ai" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">diffstir</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Differentiable Fluid Physics Parameter Identification By Stirring and For Stirring}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu*, Wenqiang and Zheng*, Dongzhe and Li, Yutong and Ren, Jieji and Lu, Cewu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{IEEE/RSJ} International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/rcare.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/rcare.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/rcare.gif-1400.webp"></source> <img src="/assets/img/publication_preview/rcare.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="rcare.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="rcare" class="col-sm-8"> <div class="title">RCare World: A Human-centric Simulation World for Caregiving Robots</div> <div class="author"> Ruolin Ye*, <strong>Wenqiang Xu*</strong>, Haoyuan Fu, Rajat Kumar Jenamani, Vy Nguyen, Cewu Lu, Katherine Dimitropoulou, and Tapomayukh Bhattacharjee</div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems</em>, 2022 <span style="color:red;font-weight: bold;">Best RoboCup Award &amp; Best Paper Finalist</span> </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2210.10821" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://emprise.cs.cornell.edu/rcareworld/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rcare</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{RCare World: A Human-centric Simulation World for Caregiving Robots}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ye*, Ruolin and Xu*, Wenqiang and Fu, Haoyuan and Jenamani, Rajat Kumar and Nguyen, Vy and Lu, Cewu and Dimitropoulou, Katherine and Bhattacharjee, Tapomayukh}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{IEEE/RSJ} International Conference on Intelligent Robots and Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{33--40}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/clothpose-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/clothpose-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/clothpose-1400.webp"></source> <img src="/assets/img/publication_preview/clothpose.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="clothpose.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="clothpose" class="col-sm-8"> <div class="title">ClothPose: A Real-World Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution</div> <div class="author"> <strong>Wenqiang Xu*</strong>, Wenxin Du*, Han Xue, Yutong Li, Ruolin Ye, Yan-Feng Wang, and Cewu Lu</div> <div class="periodical"> <em>In ICCV IEEE/CVF International Conference on Computer Vision</em>, 2023 <span style="color:red;font-weight: bold;">Oral</span> </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_ClothPose_A_Real-world_Benchmark_for_Visual_Analysis_of_Garment_Pose_ICCV_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://sites.google.com/view/clothpose" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">clothpose</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{ClothPose: A Real-World Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu*, Wenqiang and Du*, Wenxin and Xue, Han and Li, Yutong and Ye, Ruolin and Wang, Yan-Feng and Lu, Cewu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{ICCV} IEEE/CVF International Conference on Computer Vision}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{58--68}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%76%69%6E%6A%6F%68%6E@%73%6A%74%75.%65%64%75.%63%6E" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=PdzO-4YAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/robotflow-initiative" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Wenqiang Xu. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>